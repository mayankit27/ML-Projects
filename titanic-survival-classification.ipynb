{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12860382,"sourceType":"datasetVersion","datasetId":8134395,"isSourceIdPinned":false}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import necessary package","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:29.865980Z","iopub.execute_input":"2025-08-26T02:37:29.866346Z","iopub.status.idle":"2025-08-26T02:37:29.872608Z","shell.execute_reply.started":"2025-08-26T02:37:29.866322Z","shell.execute_reply":"2025-08-26T02:37:29.871156Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"load the data","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/titanic/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:29.874150Z","iopub.execute_input":"2025-08-26T02:37:29.874519Z","iopub.status.idle":"2025-08-26T02:37:29.908411Z","shell.execute_reply.started":"2025-08-26T02:37:29.874491Z","shell.execute_reply":"2025-08-26T02:37:29.907090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"explore the data ","metadata":{}},{"cell_type":"code","source":"print(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\\n\")\nprint(data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:29.910706Z","iopub.execute_input":"2025-08-26T02:37:29.911128Z","iopub.status.idle":"2025-08-26T02:37:29.931470Z","shell.execute_reply.started":"2025-08-26T02:37:29.911100Z","shell.execute_reply":"2025-08-26T02:37:29.930380Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"clean and preprocess data","metadata":{}},{"cell_type":"code","source":"\n#drop those features which are not necessary or less uswful columns\ndata=data.drop([\"Cabin\",\"Ticket\",\"Name\"],axis=1)\n\n\n#fill the missing values of age with median age\ndata[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\n\n#fill missing embarked woth most frequent port\ndata[\"Embarked\"]=data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\n\n\n#convert categorical Sex into numericals(male:0, female:1)\ndata[\"Sex\"]=data[\"Sex\"].map({\"male\":1,\"female\":0})\ndata[\"Embarked\"]=data[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n\n\nfeatures=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\nx=data[features]\ny=data[\"Survived\"]\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:29.933015Z","iopub.execute_input":"2025-08-26T02:37:29.933435Z","iopub.status.idle":"2025-08-26T02:37:29.960618Z","shell.execute_reply.started":"2025-08-26T02:37:29.933396Z","shell.execute_reply":"2025-08-26T02:37:29.959328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"split data into training and testing","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:29.962807Z","iopub.execute_input":"2025-08-26T02:37:29.963386Z","iopub.status.idle":"2025-08-26T02:37:29.983881Z","shell.execute_reply.started":"2025-08-26T02:37:29.963355Z","shell.execute_reply":"2025-08-26T02:37:29.982712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"choose a model and train the model for training data","metadata":{}},{"cell_type":"code","source":"model=LogisticRegression(max_iter=200)\nmodel.fit(x_train,y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:29.985186Z","iopub.execute_input":"2025-08-26T02:37:29.986043Z","iopub.status.idle":"2025-08-26T02:37:30.460604Z","shell.execute_reply.started":"2025-08-26T02:37:29.986004Z","shell.execute_reply":"2025-08-26T02:37:30.459340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred=model.predict(x_test)\nprint(y_pred,y_test)\naccuracy=accuracy_score(y_pred,y_test)\nprint(f\"model accuracy {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T02:37:43.318307Z","iopub.execute_input":"2025-08-26T02:37:43.318693Z","iopub.status.idle":"2025-08-26T02:37:43.331532Z","shell.execute_reply.started":"2025-08-26T02:37:43.318667Z","shell.execute_reply":"2025-08-26T02:37:43.330372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n\ndata=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\nprint(data.info())\nprint(data.head())\nprint(data.isnull().sum())\n\ndata=data.drop([\"Cabin\",\"Name\",\"Ticket\"],axis=1)\ndata[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\ndata[\"Embarked\"]=data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\n\ndata[\"Sex\"]=data[\"Sex\"].map({\"male\":1,\"female\":0})\ndata[\"Embarked\"]=data[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n\n\n\nfeatures=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\nx=data[features]\ny=data[\"Survived\"]\n\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\nmodel=LogisticRegression(max_iter=200)\nmodel.fit(x_train,y_train)\n\ny_pred=model.predict(x_test)\nprint(y_pred)\nprint(y_test)\naccuracy=accuracy_score(y_pred,y_test)\nprint(\"Model Accuracy: \",accuracy)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:03:12.892620Z","iopub.execute_input":"2025-08-26T03:03:12.893151Z","iopub.status.idle":"2025-08-26T03:03:13.379713Z","shell.execute_reply.started":"2025-08-26T03:03:12.893118Z","shell.execute_reply":"2025-08-26T03:03:13.378432Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Titanic Survival Prediction using Logistic Regression ","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n#Step-2:- Load and explore the dataset\ndata=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(\"Total null data  in each column are:-  \\n\",data.isnull().sum())\n\n#Step-3:-  Clean and preprocess the data\n#drop the features or columns that are less required\ndata=data.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n\n#Fill the missing data in age column by its median\ndata[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\n\n#Fill the missing data in Embarked column by its mode\ndata[\"Embarked\"]=data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\n\n#Convert the categorical data into numerical data\ndata[\"Sex\"]=data[\"Sex\"].map({'male':0,'female':1})\ndata[\"Embarked\"]=data[\"Embarked\"].map({'S':0,'C':1,'Q':2})\n\n#Step-4:- Selecting which features or column should be selected as input  and which one as output\nx=data.drop(\"Survived\",axis=1)\n#print(features.info())\ny=data[\"Survived\"]\n#print(\"\\n\\n\\n\",y[:10])\n\n#Step-5:- Split the trainig data into trainig and testing sets \nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-6:- Create a model and train the model by providing the training and sets\nmodel=LogisticRegression(max_iter=500)\nmodel.fit(x_train,y_train)\nprint(\"\\nModel:- \\n\",model)\n\n#Step-7:- Test the model\ny_pred=model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-8:- Calculate the accuracy\naccuracy=accuracy_score(y_pred,y_test)\nprint(f\"\\nAccuracy:- \\n{accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:09:31.213614Z","iopub.execute_input":"2025-10-06T14:09:31.214446Z","iopub.status.idle":"2025-10-06T14:09:33.073043Z","shell.execute_reply.started":"2025-10-06T14:09:31.214416Z","shell.execute_reply":"2025-10-06T14:09:33.072265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Titanic Survival Prediction using Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load the dataset\ndata=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and preprocess the data\ndata=data.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\ndata[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\ndata[\"Embarked\"]=data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\ndata[\"Sex\"]=data[\"Sex\"].map({\"male\":0,\"female\":1})\ndata[\"Embarked\"]=data[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n\n\n#Step-4:- Selecting which features will be selected as input feature and output feature \nx=data.drop([\"Survived\"],axis=1)\ny=data[\"Survived\"]\n\n#Step-5:- Split the data into training and testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-6:- Create and train the model\nrf_model=RandomForestClassifier(n_estimators=100,random_state=42)\nrf_model.fit(x_train,y_train)\nprint(\"\\nModel:- \\n\",rf_model)\n\n#Step-7:- Test the model\ny_pred=rf_model.predict(x_test)\nprint(\"\\nActual Data:- \\n\",y_test)\nprint(\"\\nPredicted Data:- \\n\",y_pred)\n\n#Step-8:-Calculate accuracy, confusion matrix, classification report\naccuracy=accuracy_score(y_pred,y_test)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_pred,y_test)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_pred,y_test)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T15:05:39.719829Z","iopub.execute_input":"2025-10-06T15:05:39.720156Z","iopub.status.idle":"2025-10-06T15:05:39.941540Z","shell.execute_reply.started":"2025-10-06T15:05:39.720134Z","shell.execute_reply":"2025-10-06T15:05:39.940810Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Titanic Survival Prediction using Support Vector Machine(SVM) Classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary Libraries \nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess the data\ndata=data.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\ndata[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\ndata[\"Embarked\"]=data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\ndata[\"Sex\"]=data[\"Sex\"].map({\"male\":0,\"female\":1})\ndata[\"Embarked\"]=data[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n\n#Step-4:- Select the features you want to keep as an input and as an output feature\nx=data.drop([\"Survived\"],axis=1)\ny=data[\"Survived\"]\n\n#Step-5:- Feature scaling because it is necessary for the SVM\nscaler=StandardScaler()\nx_scaled=scaler.fit_transform(x)\n\n#Step-6:- split the data into training and testing sets\nx_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.2,random_state=42)\n\n\n#Step-7:- Create and train the model\nsvm_model=SVC(kernel=\"rbf\",C=1,gamma=\"scale\",random_state=42)\n#svm_model=SVC(kernel=\"linear\",C=1,gamma=\"scale\",random_state=42)\n#svm_model=SVC(kernel=\"poly\",C=1,gamma=\"scale\",random_state=42)\nsvm_model.fit(x_train,y_train)\n\n#Step-8:- Test the model\ny_pred=svm_model.predict(x_test)\nprint(\"\\nActual Output:- \\n\",y_test)\nprint(\"\\nPredicted Output:- \\n\",y_pred)\n\n#Step-9:- Calculate accuracy,confusion_matrix,classification_report\naccuracy=accuracy_score(y_pred,y_test)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_pred,y_test)\nprint(\"\\nConfusion_matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_pred,y_test)\nprint(\"\\nClassification Report:- \\n\",classification_report)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T18:33:06.337903Z","iopub.execute_input":"2025-10-06T18:33:06.338223Z","iopub.status.idle":"2025-10-06T18:33:06.403694Z","shell.execute_reply.started":"2025-10-06T18:33:06.338197Z","shell.execute_reply":"2025-10-06T18:33:06.402793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Titanic Survival Prediction using Gradient boosting classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load and explore the dataset\ndata=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and preprocess the data\ndata=data.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\ndata[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\ndata[\"Embarked\"]=data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\ndata[\"Sex\"]=data[\"Sex\"].map({\"male\":0,\"female\":1})\ndata[\"Embarked\"]=data[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n\n#Step-4:- Split the data into training and tesing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-5:- Create a model and Train the model\ngb_model=GradientBoostingClassifier(n_estimators=100,learning_rate=0.1,max_depth=3,random_state=42)\ngb_model.fit(x_train,y_train)\nprint(\"Model:- \\n\",gb_model)\n\n#Step-6:- Test the model\ny_pred=gb_model.predict(x_test)\nprint(\"\\nActual Output:- \\n\",y_test)\nprint(\"\\nPredicted Output:- \\n\",y_pred)\n\n#Step-7:- Calculate accuracy,confusion_matrix,classification_report\naccuracy=accuracy_score(y_pred,y_test)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_pred,y_test)\nprint(\"\\nConfusion_matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_pred,y_test)\nprint(\"\\nClassification Report:- \\n\",classification_report)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T19:01:06.630334Z","iopub.execute_input":"2025-10-06T19:01:06.630667Z","iopub.status.idle":"2025-10-06T19:01:06.810876Z","shell.execute_reply.started":"2025-10-06T19:01:06.630640Z","shell.execute_reply":"2025-10-06T19:01:06.809911Z"}},"outputs":[],"execution_count":null}]}