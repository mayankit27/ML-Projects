{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6897944,"sourceType":"datasetVersion","datasetId":3962399}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"import necessary packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"load the data","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\ndata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"convert the text data into numerical","metadata":{}},{"cell_type":"code","source":"vectorizer=CountVectorizer()\nx=vectorizer.fit_transform(data[\"text\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"convert the data into training and testing data","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,data[\"label\"],random_state=42,test_size=0.2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"create the model and fit the model","metadata":{}},{"cell_type":"code","source":"model=MultinomialNB()\nmodel.fit(x_train,y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"predict the data and evaluate it ","metadata":{}},{"cell_type":"code","source":"y_pred=model.predict(x_test)\n\naccuracy=accuracy_score(y_test,y_pred)\n\nprint(accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_message_ham_spam(message):\n    message_vector=vectorizer.transform([message])\n    prediction=model.predict(message_vector)\n    print(prediction[0])\n    if(prediction[0]==1):\n        return \"Spam\"\n    else:\n        return \"Ham\"\n    \nprint(predict_message_ham_spam(\"can i come for dinner tomorrow\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T03:23:28.973943Z","iopub.execute_input":"2025-10-11T03:23:28.974885Z","iopub.status.idle":"2025-10-11T03:23:28.986713Z","shell.execute_reply.started":"2025-10-11T03:23:28.974848Z","shell.execute_reply":"2025-10-11T03:23:28.985536Z"}},"outputs":[{"name":"stdout","text":"0\nHam\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\n\nvectorizer=CountVectorizer()\nx=vectorizer.fit_transform(data[\"text\"])\n\nx_train,x_test,y_train,y_test=train_test_split(x,data[\"label\"],random_state=42,test_size=0.2)\n\nmodel=MultinomialNB()\nmodel.fit(x_train,y_train)\n\ny_pred=model.predict(x_test)\n\naccuracy=accuracy_score(y_test,y_pred)\nprint(accuracy)\n\ndef predict_message_ham_spam(message):\n    message_vector=vectorizer.transform([message])\n    prediction=model.predict(message_vector)\n    if(prediction==1):\n        print(\"spam\")\n    else:\n        print(\"ham\")\npredict_message_ham_spam(\"can i come to meet tomorrow, for claiming your iphone by clicking on the link\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T03:23:28.987927Z","iopub.execute_input":"2025-10-11T03:23:28.988303Z","iopub.status.idle":"2025-10-11T03:23:49.120674Z","shell.execute_reply.started":"2025-10-11T03:23:28.988268Z","shell.execute_reply":"2025-10-11T03:23:49.119421Z"}},"outputs":[{"name":"stdout","text":"0.9784901138406231\nspam\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Spam Email Detection using Multinomial Naive bayes Classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary Library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:-Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output features\nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=CountVectorizer()\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into training and testing data \nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the model\nmodel=MultinomialNB()\nmodel.fit(x_train,y_train)\nprint(\"\\nModel:- \\n\",model)\n\n#Step-8:- Test the model\ny_pred=model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T03:23:49.124094Z","iopub.execute_input":"2025-10-11T03:23:49.124407Z","iopub.status.idle":"2025-10-11T03:24:09.113098Z","shell.execute_reply.started":"2025-10-11T03:23:49.124385Z","shell.execute_reply":"2025-10-11T03:24:09.111747Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n\nModel:- \n MultinomialNB()\n\nActual data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted data:- \n [0 1 1 ... 1 0 1]\n\nAccuracy:- \n 0.9784901138406231\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def predict_message_ham_spam(message):\n    x=vectorizer.transform([message])\n    res=model.predict(x)\n    print(res)\n    if(res[0]==1):\n        print(\"Spam\")\n    else:\n        print(\"Ham\")\npredict_message_ham_spam(\"can we go for dinner tomorrow? \")\npredict_message_ham_spam(\"You got an Iphone in your lottery, for claiming your iphone click on the link\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T03:24:09.114278Z","iopub.execute_input":"2025-10-11T03:24:09.114570Z","iopub.status.idle":"2025-10-11T03:24:09.130205Z","shell.execute_reply.started":"2025-10-11T03:24:09.114548Z","shell.execute_reply":"2025-10-11T03:24:09.129074Z"}},"outputs":[{"name":"stdout","text":"[0]\nHam\n[1]\nSpam\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Spam Email Detection using Logistic Regression Classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary Library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:-Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output features\nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data \nvectorizer=CountVectorizer()\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into training and testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the model\nlg_model=LogisticRegression(max_iter=1000)\nlg_model.fit(x_train,y_train)\nprint(\"/nModel:- /n\",lg_model)\n\n#Step-8:- Test the model\ny_pred=lg_model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T03:24:09.131110Z","iopub.execute_input":"2025-10-11T03:24:09.131410Z","iopub.status.idle":"2025-10-11T03:27:01.645552Z","shell.execute_reply.started":"2025-10-11T03:24:09.131388Z","shell.execute_reply":"2025-10-11T03:27:01.643988Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n/nModel:- /n LogisticRegression(max_iter=1000)\n\nActual data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted data:- \n [0 1 1 ... 1 0 1]\n\nAccuracy:- \n 0.9864589574595566\n\nConfusion Matrix:- \n [[7800  138]\n [  88 8664]]\n\nClassification Report:- \n               precision    recall  f1-score   support\n\n           0       0.99      0.98      0.99      7938\n           1       0.98      0.99      0.99      8752\n\n    accuracy                           0.99     16690\n   macro avg       0.99      0.99      0.99     16690\nweighted avg       0.99      0.99      0.99     16690\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Spam Email Detection using KNN Classifier","metadata":{}},{"cell_type":"code","source":"#Import Necessary Library \nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n\n#Step-4:- Select input and Output features\nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=CountVectorizer()\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into Training and Testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the model\nknn_model=KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(x_train,y_train)\nprint(\"\\nModel:- \\n\",knn_model)\n\n#Step-8:- Test the model\ny_pred=knn_model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T03:27:01.646846Z","iopub.execute_input":"2025-10-11T03:27:01.647269Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n\nModel:- \n KNeighborsClassifier()\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Spam Email Detection using Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"#Import Necessary Libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output feature\nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=CountVectorizer()\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into Training and Testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the Model\ndt_model=DecisionTreeClassifier(criterion=\"entropy\",max_depth=20,random_state=42)\ndt_model.fit(x_train,y_train)\nprint(\"\\nModel:- \\n\",dt_model)\n\n#Step-8:- Test the model\ny_pred=dt_model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Spam Email Detection using Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary Libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output feature\nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer = TfidfVectorizer(max_features=10000)\nx = vectorizer.fit_transform(x)\n\n\n#Step-6:- Split the data into training and testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the Model\nrf_model = RandomForestClassifier(n_estimators=50,max_depth=20,n_jobs=-1,random_state=42)\nrf_model.fit(x_train, y_train)\nprint(\"\\nModel:- \\n\",rf_model)\n\n#Step-8:- Test the model\ny_pred=rf_model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T05:07:51.467774Z","iopub.execute_input":"2025-10-11T05:07:51.468109Z","iopub.status.idle":"2025-10-11T05:08:19.716376Z","shell.execute_reply.started":"2025-10-11T05:07:51.468086Z","shell.execute_reply":"2025-10-11T05:08:19.715216Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n\nModel:- \n RandomForestClassifier(max_depth=20, n_estimators=50, n_jobs=-1,\n                       random_state=42)\n\nActual data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted data:- \n [0 1 1 ... 1 0 1]\n\nAccuracy:- \n 0.9396045536249251\n\nConfusion Matrix:- \n [[6974  964]\n [  44 8708]]\n\nClassification Report:- \n               precision    recall  f1-score   support\n\n           0       0.99      0.88      0.93      7938\n           1       0.90      0.99      0.95      8752\n\n    accuracy                           0.94     16690\n   macro avg       0.95      0.94      0.94     16690\nweighted avg       0.94      0.94      0.94     16690\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Spam Email Classifier using SVM Classifier","metadata":{}},{"cell_type":"code","source":"#Step-1:- Import Necessary Libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n\n\n#Step-4:- Select input and output feature \nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=TfidfVectorizer(max_features=1000)\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into Training and Testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n\n#Step-7:- Create and Train the model\nsvm_model=LinearSVC()\nsvm_model.fit(x_train,y_train)\nprint(\"\\nModel:- \"svm_model)\n\n#Step-8:- Test the model\ny_pred=svm_model.predict(x_test)\nprint(\"\\nActual data:- \\n\",y_test)\nprint(\"\\nPredicted data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T05:14:17.430715Z","iopub.execute_input":"2025-10-11T05:14:17.431559Z","iopub.status.idle":"2025-10-11T05:14:37.936180Z","shell.execute_reply.started":"2025-10-11T05:14:17.431510Z","shell.execute_reply":"2025-10-11T05:14:37.934988Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n\nActual data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted data:- \n [0 0 1 ... 1 0 1]\n\nAccuracy:- \n 0.9732774116237268\n\nConfusion Matrix:- \n [[7671  267]\n [ 179 8573]]\n\nClassification Report:- \n               precision    recall  f1-score   support\n\n           0       0.98      0.97      0.97      7938\n           1       0.97      0.98      0.97      8752\n\n    accuracy                           0.97     16690\n   macro avg       0.97      0.97      0.97     16690\nweighted avg       0.97      0.97      0.97     16690\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Spam Email Prediction using Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"\n\n# Step-1:- Import Necessary libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nimport time \n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output feature \nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=TfidfVectorizer(max_features=1000)\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into Training and Testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the model\ngb_model = GradientBoostingClassifier(n_estimators=30, learning_rate=0.3, max_depth=3, random_state=42)\nstart = time.time()\ngb_model.fit(x_train, y_train)\nend = time.time()\nprint(f\"\\nModel trained in {end - start:.2f} seconds\")\nprint(\"\\nModel:- \\n\",gb_model)\n\n#Step-8:- Test the model\ny_pred=gb_model.predict(x_test)\nprint(\"\\nActual Data:- \\n\",y_test)\nprint(\"\\nPredicted Data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T05:45:45.649245Z","iopub.execute_input":"2025-10-11T05:45:45.650448Z","iopub.status.idle":"2025-10-11T05:47:23.401204Z","shell.execute_reply.started":"2025-10-11T05:45:45.650407Z","shell.execute_reply":"2025-10-11T05:47:23.400095Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n\nModel trained in 78.13 seconds\n\nModel:- \n GradientBoostingClassifier(learning_rate=0.3, n_estimators=30, random_state=42)\n\nActual Data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted Data:- \n [0 1 1 ... 1 0 1]\n\nAccuracy:- \n 0.9459556620730977\n\nConfusion Matrix:- \n [[7186  752]\n [ 150 8602]]\n\nClassification Report:- \n               precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94      7938\n           1       0.92      0.98      0.95      8752\n\n    accuracy                           0.95     16690\n   macro avg       0.95      0.94      0.95     16690\nweighted avg       0.95      0.95      0.95     16690\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"Spam Email Prediction using XGB Classifier","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Step-1:- Import Necessary libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nimport time \n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output feature \nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=TfidfVectorizer(max_features=1000)\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into Training and Testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the model\nxgb_model = XGBClassifier(\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=6,\n    use_label_encoder=False,\n    eval_metric='logloss',\n    n_jobs=-1,\n    verbosity=1\n)\nstart=time.time()\nxgb_model.fit(x_train,y_train)\nend=time.time()\nprint(f\"Training time:- {end-start:.2f} seconds\")\nprint(\"\\nModel:- \\n\",xgb_model)\n\n#Step-8:- Test the model\ny_pred=xgb_model.predict(x_test)\nprint(\"\\nActual Data:- \\n\",y_test)\nprint(\"\\nPredicted Data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T05:35:18.407173Z","iopub.execute_input":"2025-10-11T05:35:18.407563Z","iopub.status.idle":"2025-10-11T05:36:03.365770Z","shell.execute_reply.started":"2025-10-11T05:35:18.407536Z","shell.execute_reply":"2025-10-11T05:36:03.364637Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\nTraining time:- 24.54 seconds\n\nModel:- \n XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n\nActual Data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted Data:- \n [0 1 1 ... 1 0 1]\n\nAccuracy:- \n 0.9690832834032355\n\nConfusion Matrix:- \n [[7485  453]\n [  63 8689]]\n\nClassification Report:- \n               precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97      7938\n           1       0.95      0.99      0.97      8752\n\n    accuracy                           0.97     16690\n   macro avg       0.97      0.97      0.97     16690\nweighted avg       0.97      0.97      0.97     16690\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Spam Email Prediction using LightGBM Classifier","metadata":{}},{"cell_type":"code","source":"\n\n# Step-1:- Import Necessary libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nimport time \n\n#Step-2:- Load and Explore the dataset\ndata=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")\nprint(data.head())\nprint(\"\\n\\n\\n\\n\")\nprint(data.info())\nprint(\"\\n\\n\\n\\n\")\nprint(data.isnull().sum())\nprint(\"\\n\\n\\n\\n\")\n\n#Step-3:- Clean and Preprocess data \n#As dataset is already clean, so there is no need of cleaning the data \n\n#Step-4:- Select input and output feature \nx=data[\"text\"]\ny=data[\"label\"]\n\n#Step-5:- Convert text data into numerical data\nvectorizer=TfidfVectorizer(max_features=1000)\nx=vectorizer.fit_transform(x)\n\n#Step-6:- Split the data into Training and Testing sets\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\n#Step-7:- Create and Train the model\nlgb_model = lgb.LGBMClassifier(n_estimators=100,learning_rate=0.1,max_depth=-1,n_jobs=-1,random_state=42)\nstart = time.time()\nlgb_model.fit(x_train, y_train)\nend = time.time()\nprint(f\"\\nTraining Time: {end - start:.2f} seconds\")\nprint(\"\\nModel:- \\n\",lgb_model)\n\n#Step-8:- Test the model\ny_pred=lgb_model.predict(x_test)\nprint(\"\\nActual Data:- \\n\",y_test)\nprint(\"\\nPredicted Data:- \\n\",y_pred)\n\n#Step-9:- Model Evaluation(Calculate accuracy)\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"\\nAccuracy:- \\n\",accuracy)\nconfusion_matrix=confusion_matrix(y_test,y_pred)\nprint(\"\\nConfusion Matrix:- \\n\",confusion_matrix)\nclassification_report=classification_report(y_test,y_pred)\nprint(\"\\nClassification Report:- \\n\",classification_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T05:51:25.057790Z","iopub.execute_input":"2025-10-11T05:51:25.059657Z","iopub.status.idle":"2025-10-11T05:51:58.710514Z","shell.execute_reply.started":"2025-10-11T05:51:25.059576Z","shell.execute_reply":"2025-10-11T05:51:58.709415Z"}},"outputs":[{"name":"stdout","text":"   label                                               text\n0      1  ounce feather bowl hummingbird opec moment ala...\n1      1  wulvob get your medircations online qnb ikud v...\n2      0   computer connection from cnn com wednesday es...\n3      1  university degree obtain a prosperous future m...\n4      0  thanks for all your answers guys i know i shou...\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83448 entries, 0 to 83447\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   label   83448 non-null  int64 \n 1   text    83448 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 1.3+ MB\nNone\n\n\n\n\n\nlabel    0\ntext     0\ndtype: int64\n\n\n\n\n\n[LightGBM] [Info] Number of positive: 35158, number of negative: 31600\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.400296 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 249004\n[LightGBM] [Info] Number of data points in the train set: 66758, number of used features: 1000\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.526648 -> initscore=0.106695\n[LightGBM] [Info] Start training from score 0.106695\n\nTraining Time: 12.53 seconds\n\nModel:- \n LGBMClassifier(n_jobs=-1, random_state=42)\n\nActual Data:- \n 67681    0\n61385    1\n41829    1\n29172    1\n35274    0\n        ..\n70371    1\n3624     1\n31079    1\n11145    0\n13048    1\nName: label, Length: 16690, dtype: int64\n\nPredicted Data:- \n [0 1 1 ... 1 0 1]\n\nAccuracy:- \n 0.980407429598562\n\nConfusion Matrix:- \n [[7695  243]\n [  84 8668]]\n\nClassification Report:- \n               precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98      7938\n           1       0.97      0.99      0.98      8752\n\n    accuracy                           0.98     16690\n   macro avg       0.98      0.98      0.98     16690\nweighted avg       0.98      0.98      0.98     16690\n\n","output_type":"stream"}],"execution_count":23}]}